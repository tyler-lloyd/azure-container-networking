parameters:
  dependsOn: ""
  name: "cilium"
  clusterType: "overlay-byocni-nokubeproxy-up"
  clusterName: "cilium-overlay"
  nodeCount: 10
  vmSize: "Standard_DS4_v2"
  os: "linux"
  arch: ""
  osSKU: Ubuntu
  hubbleEnabled: false
  dualstackVersion: ""
  cni: "cilium"

# Condition confirms that:
# Previous job has reported Succeeded. Previous job is currently setup which controls variable assignment and we are dependent on its success.
# CONTROL_CNI either contains 'cniv1' or 'all'. It is not case sensitive
stages:
  - stage: create_${{ parameters.name }}
    condition: and( succeeded(), and( or( contains(variables.CONTROL_CNI, 'cilium') , contains(variables.CONTROL_CNI, 'all') ), or( contains(variables.CONTROL_OS, 'linux'), contains(variables.CONTROL_OS, 'all') ) ) )
    variables:
      ${{ if contains(parameters.clusterName, 'rdma') }}:
        location: $(LOCATION_RDMA)
      ${{ elseif eq(parameters.arch, 'arm64') }}:
        location: $(LOCATION_ARM64)
      ${{ else }}:
        location: $(LOCATION_AMD64)
      commitID: $[ stagedependencies.setup.env.outputs['SetEnvVars.commitID'] ]
    dependsOn:
      - setup
      - build_images
    displayName: "Create Cluster - ${{ parameters.clusterName }}"
    jobs:
      - job: create_aks_cluster_with_${{ parameters.name }}
        pool:
          name: "$(BUILD_POOL_NAME_DEFAULT)"
        steps:
          - template: ../load-test-templates/create-cluster-template.yaml
            parameters:
              clusterType: ${{ parameters.clusterType }}
              clusterName: ${{ parameters.clusterName }}-$(commitID)
              nodeCount: ${{ parameters.nodeCount }}
              vmSize: ${{ parameters.vmSize }}
              region: $(location)

# Conditions for below E2E test scenarios confirm that:
# Pipeline has not been canceled and that the previous job has reports anything other than failure(Succeeded, SuccededWithIssues, Skipped). Previous job is declared by dependsOn:
# CONTROL_SCENARIO either contains 'all' or its respective scenario 'npm', 'scaleTest', 'restartNode', 'restartCNS'. It is not case sensitive
# Ex. CONTROL_SCENARIO = "restartnode SCALETEST" will only run Scale Test and Restart Test.
  - stage: ${{ parameters.name }}
    variables:
      commitID: $[ stagedependencies.setup.env.outputs['SetEnvVars.commitID'] ]
      cnsVersion: $[ stagedependencies.setup.env.outputs['SetEnvVars.cnsVersion'] ]
      ${{ if contains(parameters.clusterName, 'rdma') }}:
        location: $(LOCATION_RDMA)
      ${{ elseif eq(parameters.arch, 'arm64') }}:
        location: $(LOCATION_ARM64)
      ${{ else }}:
        location: $(LOCATION_AMD64)
    pool:
      name: "$(BUILD_POOL_NAME_DEFAULT)"
    dependsOn:
      - create_${{ parameters.name }}
      - publish
      - setup
    displayName: "Cilium Test - ${{ parameters.name }}"
    jobs:
      - ${{if eq(parameters.hubbleEnabled, false)}}:
        - job: deploy_cilium_components
          displayName: Deploy Cilium
          steps:
            - task: AzureCLI@2
              displayName: "Install Cilium, CNS, and ip-masq-agent"
              inputs:
                azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
                scriptLocation: "inlineScript"
                scriptType: "bash"
                addSpnToEnvironment: true
                inlineScript: |
                  set -ex
                  az extension add --name aks-preview
                  make -C ./hack/aks set-kubeconf AZCLI=az CLUSTER=${{ parameters.clusterName }}-$(commitID)
                  ls -lah
                  pwd
                  kubectl cluster-info
                  kubectl get po -owide -A

                  if [ ! -z ${{ parameters.dualstackVersion }} ]; then
                    echo "Use dualstack version of Cilium"
                    export CILIUM_VERSION_TAG=${{ parameters.dualstackVersion }}
                  fi

                  echo "install Cilium ${CILIUM_VERSION_TAG}"
                  export DIR=$(echo ${CILIUM_VERSION_TAG#v} | cut -d. -f1,2)
                  echo "installing files from ${DIR}"

                  echo "deploy Cilium ConfigMap"
                  if [ ! -z ${{ parameters.dualstackVersion }} ]; then
                    echo "Use dualstack configmap for Cilium"
                    kubectl apply -f test/integration/manifests/cilium/v${DIR}/cilium-config/cilium-config-dualstack.yaml
                  else
                    kubectl apply -f test/integration/manifests/cilium/v${DIR}/cilium-config/cilium-config.yaml
                  fi

                  # Passes Cilium image to daemonset and deployment
                  kubectl apply -f test/integration/manifests/cilium/v${DIR}/cilium-agent/files
                  kubectl apply -f test/integration/manifests/cilium/v${DIR}/cilium-operator/files

                  if [ ! -z ${{ parameters.dualstackVersion }} ]; then
                    echo "Use dualstack daemonset for Cilium"
                    export IPV6_HP_BPF_VERSION=$(make ipv6-hp-bpf-version)
                    envsubst '${CILIUM_VERSION_TAG},${CILIUM_IMAGE_REGISTRY},${IPV6_HP_BPF_VERSION}' < test/integration/manifests/cilium/v${DIR}/cilium-agent/templates/daemonset-dualstack.yaml | kubectl apply -f -
                  else
                    envsubst '${CILIUM_VERSION_TAG},${CILIUM_IMAGE_REGISTRY}' < test/integration/manifests/cilium/v${DIR}/cilium-agent/templates/daemonset.yaml | kubectl apply -f -
                  fi

                  envsubst '${CILIUM_VERSION_TAG},${CILIUM_IMAGE_REGISTRY}' < test/integration/manifests/cilium/v${DIR}/cilium-operator/templates/deployment.yaml | kubectl apply -f -
                  kubectl get po -owide -A

                  echo "Deploy Azure-CNS"
                  sudo -E env "PATH=$PATH" make test-integration AZURE_IPAM_VERSION=$(make azure-ipam-version) CNS_VERSION=$(make cns-version) INSTALL_CNS=true INSTALL_OVERLAY=true CNS_IMAGE_REPO=$(CNS_IMAGE_REPO)
                  kubectl get po -owide -A
      - ${{if eq(parameters.hubbleEnabled, true)}}:
        - job: deploy_cilium_components
          displayName: Deploy Cilium with Hubble
          steps:
            - task: AzureCLI@2
              displayName: "Install Cilium, CNS, and ip-masq-agent"
              inputs:
                azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
                scriptLocation: "inlineScript"
                scriptType: "bash"
                addSpnToEnvironment: true
                inlineScript: |
                  set -ex
                  az extension add --name aks-preview
                  make -C ./hack/aks set-kubeconf AZCLI=az CLUSTER=${{ parameters.clusterName }}-$(commitID)
                  ls -lah
                  pwd
                  kubectl cluster-info
                  kubectl get po -owide -A

                  echo "install Cilium onto Overlay Cluster with hubble enabled"
                  export CILIUM_VERSION_TAG=${CILIUM_HUBBLE_VERSION_TAG}
                  export DIR=${CILIUM_VERSION_TAG%.*}
                  echo "installing files from ${DIR}"
                  kubectl apply -f test/integration/manifests/cilium/v${DIR}/cilium-config/cilium-config-hubble.yaml
                  kubectl apply -f test/integration/manifests/cilium/v${DIR}/cilium-agent/files
                  kubectl apply -f test/integration/manifests/cilium/v${DIR}/cilium-operator/files
                  envsubst '${CILIUM_IMAGE_REGISTRY},${CILIUM_VERSION_TAG}' < test/integration/manifests/cilium/v${DIR}/cilium-agent/templates/daemonset.yaml | kubectl apply -f -
                  envsubst '${CILIUM_IMAGE_REGISTRY},${CILIUM_VERSION_TAG}' < test/integration/manifests/cilium/v${DIR}/cilium-operator/templates/deployment.yaml | kubectl apply -f -
                  kubectl get po -owide -A

                  echo "Deploy Azure-CNS"
                  sudo -E env "PATH=$PATH" make test-integration AZURE_IPAM_VERSION=$(make azure-ipam-version) CNS_VERSION=$(make cns-version) INSTALL_CNS=true INSTALL_OVERLAY=true CNS_IMAGE_REPO=$(CNS_IMAGE_REPO)
                  kubectl get po -owide -A

      - job: deploy_pods
        condition: and( and( not(canceled()), not(failed()) ), or( contains(variables.CONTROL_SCENARIO, 'scaleTest') , contains(variables.CONTROL_SCENARIO, 'all') ) )
        displayName: "Scale Test"
        dependsOn: deploy_cilium_components
        steps:
          - template: ../load-test-templates/pod-deployment-template.yaml
            parameters:
              clusterName: ${{ parameters.clusterName }}-$(commitID)
              scaleup: ${SCALEUP_CILIUM}
              os: linux
              iterations: ${ITERATIONS_CILIUM}
              nodeCount: ${{ parameters.nodeCount }}
              cni: cilium
          - template: ../load-test-templates/validate-state-template.yaml
            parameters:
              clusterName: ${{ parameters.clusterName }}-$(commitID)
              cni: ${{ parameters.cni }}
      - job: restart_nodes
        condition: and( and( not(canceled()), not(failed()) ), or( contains(variables.CONTROL_SCENARIO, 'restartNode') , contains(variables.CONTROL_SCENARIO, 'all') ) )
        displayName: "Restart Test"
        dependsOn: deploy_pods
        steps:
          - template: ../load-test-templates/restart-node-template.yaml
            parameters:
              clusterName: ${{ parameters.clusterName }}-$(commitID)
              os: ${{ parameters.os }}
              cni: cilium
              region: $(location)
          - template: ../load-test-templates/validate-state-template.yaml
            parameters:
              clusterName: ${{ parameters.clusterName }}-$(commitID)
              restartCase: "true"
              cni: ${{ parameters.cni }}
      - job: restart_cns
        condition: and( and( not(canceled()), not(failed()) ), or( contains(variables.CONTROL_SCENARIO, 'restartCNS') , contains(variables.CONTROL_SCENARIO, 'all') ) )
        displayName: "Restart and Validate CNS"
        dependsOn: restart_nodes
        steps:
          - template: ../load-test-templates/restart-cns-template.yaml
            parameters:
              clusterName: ${{ parameters.clusterName }}-$(commitID)
              os: ${{ parameters.os }}
              scaleup: ${SCALEUP_CILIUM}
              nodeCount: ${{ parameters.nodeCount }}
              cni: ${{ parameters.cni }}
      - job: cni_tests
        displayName: "Cilium Test"
        dependsOn: restart_cns
        steps:
          - template: ../../templates/cilium-cli.yaml
          - task: AzureCLI@2
            inputs:
              azureSubscription: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
              scriptLocation: "inlineScript"
              scriptType: "bash"
              addSpnToEnvironment: true
              inlineScript: |
                set -ex
                make -C ./hack/aks set-kubeconf AZCLI=az CLUSTER=${{ parameters.clusterName }}-$(commitID)
            name: "GetCluster"
            displayName: "Get AKS Cluster"
          - script: |
              kubectl delete ns load-test
              cilium connectivity test --connect-timeout 4s --request-timeout 30s --test '!pod-to-pod-encryption,!node-to-node-encryption'
            retryCountOnTaskFailure: 6
            name: "CiliumConnectivityTests"
            displayName: "Run Cilium Connectivity Tests"
          - script: |
              cd hack/scripts
              chmod +x async-delete-test.sh
              ./async-delete-test.sh
              if ! [ -z $(kubectl -n kube-system get ds azure-cns | grep non-existing) ]; then
                kubectl -n kube-system patch daemonset azure-cns --type json -p='[{"op": "remove", "path": "/spec/template/spec/nodeSelector/non-existing"}]'
              fi
            name: "testAsyncDelete"
            displayName: "Verify Async Delete when CNS is down"
      - template: ../k8s-e2e/k8s-e2e-job-template.yaml
        parameters:
          sub: $(BUILD_VALIDATIONS_SERVICE_CONNECTION)
          clusterName: ${{ parameters.clusterName }}-$(commitID)
          os: ${{ parameters.os }}
          cni: cilium
          dependsOn: cni_tests
          dns: true
          portforward: true
          service: true
          ${{ if eq(parameters.dualstackVersion, '') }}:
            datapath: true
          ${{ else }}:
            dualstack: true
      - job: failedE2ELogs
        displayName: "Failure Logs"
        dependsOn:
          - deploy_cilium_components
          - deploy_pods
          - restart_nodes
          - restart_cns
          - cni_tests
          - cni_${{ parameters.os }}
        condition: failed()
        steps:
          - template: ../../templates/log-template.yaml
            parameters:
              clusterName: ${{ parameters.clusterName }}-$(commitID)
              os: linux
              cni: cilium
